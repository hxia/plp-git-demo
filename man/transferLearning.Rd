% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DeepNN.R
\name{transferLearning}
\alias{transferLearning}
\title{[Under development] Transfer learning}
\usage{
transferLearning(
  plpResult,
  plpData,
  population,
  fixLayers = T,
  includeTop = F,
  addLayers = c(100, 10),
  layerDropout = c(T, T),
  layerActivation = c("relu", "softmax"),
  outcomeWeight = 1,
  batchSize = 10000,
  epochs = 20
)
}
\arguments{
\item{plpResult}{The plp result when training a kersa deep learning model on big data}

\item{plpData}{The new data to fine tune the model on}

\item{population}{The population for the new data}

\item{fixLayers}{boolean specificying whether to fix weights in model being transferred}

\item{includeTop}{If TRUE the final layer of the model being transferred is removed}

\item{addLayers}{vector specifying nodes in each layer to add e.g. c(100,10) will add another layer with 100 nodels and then a final layer with 10}

\item{layerDropout}{Add dropout to each new layer (binary vector length of addLayers)}

\item{layerActivation}{Activation function for each new layer (string vector length of addLayers)}

\item{outcomeWeight}{The weight to assign the class 1 when training the model}

\item{batchSize}{Size of each batch for updating layers}

\item{epochs}{Number of epoches to run}
}
\description{
[Under development] Transfer learning
}
\examples{
\dontrun{
modelSet <- setDeepNN()
plpResult <- runPlp(plpData, population, modelSettings = modelSet, ...)

transferLearning(...)
}
}
